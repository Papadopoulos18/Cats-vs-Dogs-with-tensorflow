{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-catalyst",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aggelos\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\aggelos\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\aggelos\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\aggelos\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\aggelos\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\aggelos\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\aggelos\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\aggelos\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\aggelos\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\aggelos\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\aggelos\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\aggelos\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-conv-32-nodes-0-dense-1612712168\n",
      "WARNING:tensorflow:From C:\\Users\\aggelos\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\aggelos\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 22415 samples, validate on 2491 samples\n",
      "Epoch 1/10\n",
      "22415/22415 [==============================] - 24s 1ms/sample - loss: 0.6268 - acc: 0.6483 - val_loss: 0.5835 - val_acc: 0.7045\n",
      "Epoch 2/10\n",
      "22415/22415 [==============================] - 26s 1ms/sample - loss: 0.5567 - acc: 0.7194 - val_loss: 0.5617 - val_acc: 0.7130\n",
      "Epoch 3/10\n",
      "22415/22415 [==============================] - 24s 1ms/sample - loss: 0.5252 - acc: 0.7463 - val_loss: 0.5353 - val_acc: 0.7367\n",
      "Epoch 4/10\n",
      "22415/22415 [==============================] - 24s 1ms/sample - loss: 0.5022 - acc: 0.7600 - val_loss: 0.5353 - val_acc: 0.7395\n",
      "Epoch 5/10\n",
      "22415/22415 [==============================] - 23s 1ms/sample - loss: 0.4817 - acc: 0.7747 - val_loss: 0.5192 - val_acc: 0.7599\n",
      "Epoch 6/10\n",
      "22415/22415 [==============================] - 24s 1ms/sample - loss: 0.4664 - acc: 0.7804 - val_loss: 0.5179 - val_acc: 0.7583\n",
      "Epoch 7/10\n",
      "22415/22415 [==============================] - 25s 1ms/sample - loss: 0.4566 - acc: 0.7871 - val_loss: 0.5235 - val_acc: 0.7507\n",
      "Epoch 8/10\n",
      "22415/22415 [==============================] - 25s 1ms/sample - loss: 0.4448 - acc: 0.7963 - val_loss: 0.5089 - val_acc: 0.7595\n",
      "Epoch 9/10\n",
      "22415/22415 [==============================] - 25s 1ms/sample - loss: 0.4353 - acc: 0.8005 - val_loss: 0.5390 - val_acc: 0.7423\n",
      "Epoch 10/10\n",
      "22415/22415 [==============================] - 24s 1ms/sample - loss: 0.4282 - acc: 0.8031 - val_loss: 0.5316 - val_acc: 0.7507\n",
      "2-conv-32-nodes-0-dense-1612712414\n",
      "Train on 22415 samples, validate on 2491 samples\n",
      "Epoch 1/10\n",
      "22415/22415 [==============================] - 51s 2ms/sample - loss: 0.6173 - acc: 0.6541 - val_loss: 0.5727 - val_acc: 0.7037\n",
      "Epoch 2/10\n",
      "22415/22415 [==============================] - 55s 2ms/sample - loss: 0.5312 - acc: 0.7372 - val_loss: 0.4973 - val_acc: 0.7615\n",
      "Epoch 3/10\n",
      "22415/22415 [==============================] - 49s 2ms/sample - loss: 0.4931 - acc: 0.7628 - val_loss: 0.5100 - val_acc: 0.7523\n",
      "Epoch 4/10\n",
      "22415/22415 [==============================] - 48s 2ms/sample - loss: 0.4725 - acc: 0.7769 - val_loss: 0.4753 - val_acc: 0.7768\n",
      "Epoch 5/10\n",
      "22415/22415 [==============================] - 58s 3ms/sample - loss: 0.4515 - acc: 0.7917 - val_loss: 0.4518 - val_acc: 0.7949\n",
      "Epoch 6/10\n",
      "22415/22415 [==============================] - 50s 2ms/sample - loss: 0.4379 - acc: 0.8008 - val_loss: 0.4393 - val_acc: 0.7957\n",
      "Epoch 7/10\n",
      "22415/22415 [==============================] - 50s 2ms/sample - loss: 0.4210 - acc: 0.8080 - val_loss: 0.4435 - val_acc: 0.7973\n",
      "Epoch 8/10\n",
      "22415/22415 [==============================] - 53s 2ms/sample - loss: 0.4065 - acc: 0.8165 - val_loss: 0.4242 - val_acc: 0.8097\n",
      "Epoch 9/10\n",
      "22415/22415 [==============================] - 58s 3ms/sample - loss: 0.3906 - acc: 0.8239 - val_loss: 0.4191 - val_acc: 0.8177\n",
      "Epoch 10/10\n",
      "22415/22415 [==============================] - 56s 2ms/sample - loss: 0.3761 - acc: 0.8323 - val_loss: 0.4196 - val_acc: 0.8141\n",
      "3-conv-32-nodes-0-dense-1612712943\n",
      "Train on 22415 samples, validate on 2491 samples\n",
      "Epoch 1/10\n",
      "22415/22415 [==============================] - 56s 3ms/sample - loss: 0.6479 - acc: 0.6104 - val_loss: 0.5889 - val_acc: 0.6841\n",
      "Epoch 2/10\n",
      "22415/22415 [==============================] - 55s 2ms/sample - loss: 0.5602 - acc: 0.7127 - val_loss: 0.5350 - val_acc: 0.7322\n",
      "Epoch 3/10\n",
      "22415/22415 [==============================] - 53s 2ms/sample - loss: 0.5123 - acc: 0.7514 - val_loss: 0.5326 - val_acc: 0.7407\n",
      "Epoch 4/10\n",
      "22415/22415 [==============================] - 59s 3ms/sample - loss: 0.4788 - acc: 0.7724 - val_loss: 0.4952 - val_acc: 0.7668\n",
      "Epoch 5/10\n",
      "22415/22415 [==============================] - 60s 3ms/sample - loss: 0.4581 - acc: 0.7852 - val_loss: 0.4777 - val_acc: 0.7732\n",
      "Epoch 6/10\n",
      "22415/22415 [==============================] - 56s 3ms/sample - loss: 0.4385 - acc: 0.7989 - val_loss: 0.4542 - val_acc: 0.7904\n",
      "Epoch 7/10\n",
      "22415/22415 [==============================] - 50s 2ms/sample - loss: 0.4146 - acc: 0.8125 - val_loss: 0.4572 - val_acc: 0.7916\n",
      "Epoch 8/10\n",
      "22415/22415 [==============================] - 50s 2ms/sample - loss: 0.4025 - acc: 0.8169 - val_loss: 0.4562 - val_acc: 0.7860\n",
      "Epoch 9/10\n",
      "22415/22415 [==============================] - 55s 2ms/sample - loss: 0.3852 - acc: 0.8264 - val_loss: 0.4442 - val_acc: 0.7953\n",
      "Epoch 10/10\n",
      "22415/22415 [==============================] - 57s 3ms/sample - loss: 0.3730 - acc: 0.8330 - val_loss: 0.4487 - val_acc: 0.7957\n",
      "1-conv-64-nodes-0-dense-1612713499\n",
      "Train on 22415 samples, validate on 2491 samples\n",
      "Epoch 1/10\n",
      "22415/22415 [==============================] - 42s 2ms/sample - loss: 0.6238 - acc: 0.6502 - val_loss: 0.5813 - val_acc: 0.6917\n",
      "Epoch 2/10\n",
      "22415/22415 [==============================] - 41s 2ms/sample - loss: 0.5501 - acc: 0.7230 - val_loss: 0.5508 - val_acc: 0.7294\n",
      "Epoch 3/10\n",
      "22415/22415 [==============================] - 43s 2ms/sample - loss: 0.5131 - acc: 0.7527 - val_loss: 0.5238 - val_acc: 0.7483\n",
      "Epoch 4/10\n",
      "22415/22415 [==============================] - 45s 2ms/sample - loss: 0.4877 - acc: 0.7653 - val_loss: 0.5098 - val_acc: 0.7523\n",
      "Epoch 5/10\n",
      "22415/22415 [==============================] - 42s 2ms/sample - loss: 0.4686 - acc: 0.7760 - val_loss: 0.5323 - val_acc: 0.7391\n",
      "Epoch 6/10\n",
      "22415/22415 [==============================] - 42s 2ms/sample - loss: 0.4506 - acc: 0.7910 - val_loss: 0.5384 - val_acc: 0.7330\n",
      "Epoch 7/10\n",
      "22415/22415 [==============================] - 43s 2ms/sample - loss: 0.4346 - acc: 0.8001 - val_loss: 0.5243 - val_acc: 0.7515\n",
      "Epoch 8/10\n",
      "22415/22415 [==============================] - 43s 2ms/sample - loss: 0.4177 - acc: 0.8099 - val_loss: 0.5336 - val_acc: 0.7363\n",
      "Epoch 9/10\n",
      "22415/22415 [==============================] - 49s 2ms/sample - loss: 0.4017 - acc: 0.8180 - val_loss: 0.5280 - val_acc: 0.7403\n",
      "Epoch 10/10\n",
      "22415/22415 [==============================] - 46s 2ms/sample - loss: 0.3883 - acc: 0.8239 - val_loss: 0.5640 - val_acc: 0.7274\n",
      "2-conv-64-nodes-0-dense-1612713939\n",
      "Train on 22415 samples, validate on 2491 samples\n",
      "Epoch 1/10\n",
      "22415/22415 [==============================] - 104s 5ms/sample - loss: 0.6097 - acc: 0.6581 - val_loss: 0.5414 - val_acc: 0.7346\n",
      "Epoch 2/10\n",
      "22415/22415 [==============================] - 102s 5ms/sample - loss: 0.5195 - acc: 0.7450 - val_loss: 0.4973 - val_acc: 0.7547\n",
      "Epoch 3/10\n",
      "22415/22415 [==============================] - 104s 5ms/sample - loss: 0.4821 - acc: 0.7709 - val_loss: 0.4709 - val_acc: 0.7800\n",
      "Epoch 4/10\n",
      "22415/22415 [==============================] - 113s 5ms/sample - loss: 0.4508 - acc: 0.7902 - val_loss: 0.4594 - val_acc: 0.7844\n",
      "Epoch 5/10\n",
      "22415/22415 [==============================] - 108s 5ms/sample - loss: 0.4274 - acc: 0.8035 - val_loss: 0.4423 - val_acc: 0.8033\n",
      "Epoch 6/10\n",
      "22415/22415 [==============================] - 111s 5ms/sample - loss: 0.4033 - acc: 0.8174 - val_loss: 0.4758 - val_acc: 0.7744\n",
      "Epoch 7/10\n",
      "22415/22415 [==============================] - 114s 5ms/sample - loss: 0.3850 - acc: 0.8276 - val_loss: 0.4417 - val_acc: 0.7993\n",
      "Epoch 8/10\n",
      "22415/22415 [==============================] - 106s 5ms/sample - loss: 0.3700 - acc: 0.8333 - val_loss: 0.4214 - val_acc: 0.8145\n",
      "Epoch 9/10\n",
      "22415/22415 [==============================] - 108s 5ms/sample - loss: 0.3500 - acc: 0.8461 - val_loss: 0.4399 - val_acc: 0.7981\n",
      "Epoch 10/10\n",
      "22415/22415 [==============================] - 106s 5ms/sample - loss: 0.3377 - acc: 0.8517 - val_loss: 0.4245 - val_acc: 0.8097\n",
      "3-conv-64-nodes-0-dense-1612715020\n",
      "Train on 22415 samples, validate on 2491 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22415/22415 [==============================] - 121s 5ms/sample - loss: 0.6264 - acc: 0.6427 - val_loss: 0.5980 - val_acc: 0.6736\n",
      "Epoch 2/10\n",
      "22415/22415 [==============================] - 122s 5ms/sample - loss: 0.5175 - acc: 0.7465 - val_loss: 0.4971 - val_acc: 0.7680\n",
      "Epoch 3/10\n",
      "22415/22415 [==============================] - 114s 5ms/sample - loss: 0.4714 - acc: 0.7775 - val_loss: 0.4580 - val_acc: 0.7921\n",
      "Epoch 4/10\n",
      "22415/22415 [==============================] - 115s 5ms/sample - loss: 0.4341 - acc: 0.7994 - val_loss: 0.4399 - val_acc: 0.8025\n",
      "Epoch 5/10\n",
      "22415/22415 [==============================] - 139s 6ms/sample - loss: 0.3989 - acc: 0.8202 - val_loss: 0.4334 - val_acc: 0.7977\n",
      "Epoch 6/10\n",
      "22415/22415 [==============================] - 131s 6ms/sample - loss: 0.3738 - acc: 0.8328 - val_loss: 0.3991 - val_acc: 0.8145\n",
      "Epoch 7/10\n",
      "22415/22415 [==============================] - 125s 6ms/sample - loss: 0.3469 - acc: 0.8451 - val_loss: 0.4021 - val_acc: 0.8149\n",
      "Epoch 8/10\n",
      "22415/22415 [==============================] - 125s 6ms/sample - loss: 0.3190 - acc: 0.8625 - val_loss: 0.3956 - val_acc: 0.8238\n",
      "Epoch 9/10\n",
      "22415/22415 [==============================] - 126s 6ms/sample - loss: 0.2932 - acc: 0.8733 - val_loss: 0.3891 - val_acc: 0.8266\n",
      "Epoch 10/10\n",
      "22415/22415 [==============================] - 133s 6ms/sample - loss: 0.2734 - acc: 0.8846 - val_loss: 0.4022 - val_acc: 0.8210\n",
      "1-conv-128-nodes-0-dense-1612716279\n",
      "Train on 22415 samples, validate on 2491 samples\n",
      "Epoch 1/10\n",
      "22415/22415 [==============================] - 97s 4ms/sample - loss: 0.6095 - acc: 0.6675 - val_loss: 0.5573 - val_acc: 0.7266\n",
      "Epoch 2/10\n",
      "22415/22415 [==============================] - 100s 4ms/sample - loss: 0.5344 - acc: 0.7362 - val_loss: 0.5305 - val_acc: 0.7423\n",
      "Epoch 3/10\n",
      "22415/22415 [==============================] - 96s 4ms/sample - loss: 0.5022 - acc: 0.7582 - val_loss: 0.5169 - val_acc: 0.7475\n",
      "Epoch 4/10\n",
      "22415/22415 [==============================] - 96s 4ms/sample - loss: 0.4780 - acc: 0.7750 - val_loss: 0.5247 - val_acc: 0.7399\n",
      "Epoch 5/10\n",
      "22415/22415 [==============================] - 97s 4ms/sample - loss: 0.4555 - acc: 0.7879 - val_loss: 0.5510 - val_acc: 0.7338\n",
      "Epoch 6/10\n",
      "22415/22415 [==============================] - 95s 4ms/sample - loss: 0.4352 - acc: 0.7999 - val_loss: 0.5424 - val_acc: 0.7350\n",
      "Epoch 7/10\n",
      "22415/22415 [==============================] - 85s 4ms/sample - loss: 0.4157 - acc: 0.8103 - val_loss: 0.5307 - val_acc: 0.7427\n",
      "Epoch 8/10\n",
      "22415/22415 [==============================] - 91s 4ms/sample - loss: 0.3958 - acc: 0.8211 - val_loss: 0.5350 - val_acc: 0.7519\n",
      "Epoch 9/10\n",
      "22415/22415 [==============================] - 94s 4ms/sample - loss: 0.3776 - acc: 0.8317 - val_loss: 0.5396 - val_acc: 0.7403\n",
      "Epoch 10/10\n",
      "22415/22415 [==============================] - 92s 4ms/sample - loss: 0.3570 - acc: 0.8421 - val_loss: 0.5587 - val_acc: 0.7358\n",
      "2-conv-128-nodes-0-dense-1612717233\n",
      "Train on 22415 samples, validate on 2491 samples\n",
      "Epoch 1/10\n",
      "22415/22415 [==============================] - 281s 13ms/sample - loss: 0.6138 - acc: 0.6550 - val_loss: 0.5849 - val_acc: 0.6873\n",
      "Epoch 2/10\n",
      "22415/22415 [==============================] - 273s 12ms/sample - loss: 0.5192 - acc: 0.7466 - val_loss: 0.5057 - val_acc: 0.7579\n",
      "Epoch 3/10\n",
      "22415/22415 [==============================] - 269s 12ms/sample - loss: 0.4822 - acc: 0.7706 - val_loss: 0.4724 - val_acc: 0.7736\n",
      "Epoch 4/10\n",
      "22415/22415 [==============================] - 268s 12ms/sample - loss: 0.4535 - acc: 0.7876 - val_loss: 0.4756 - val_acc: 0.7728\n",
      "Epoch 5/10\n",
      "22415/22415 [==============================] - 273s 12ms/sample - loss: 0.4337 - acc: 0.7997 - val_loss: 0.4737 - val_acc: 0.7800\n",
      "Epoch 6/10\n",
      "22415/22415 [==============================] - 285s 13ms/sample - loss: 0.4089 - acc: 0.8140 - val_loss: 0.4411 - val_acc: 0.7945\n",
      "Epoch 7/10\n",
      "22415/22415 [==============================] - 301s 13ms/sample - loss: 0.3888 - acc: 0.8245 - val_loss: 0.4642 - val_acc: 0.7892\n",
      "Epoch 8/10\n",
      "22415/22415 [==============================] - 345s 15ms/sample - loss: 0.3685 - acc: 0.8363 - val_loss: 0.4669 - val_acc: 0.7868\n",
      "Epoch 9/10\n",
      "22415/22415 [==============================] - 383s 17ms/sample - loss: 0.3470 - acc: 0.8453 - val_loss: 0.4276 - val_acc: 0.8077\n",
      "Epoch 10/10\n",
      "22415/22415 [==============================] - 362s 16ms/sample - loss: 0.3302 - acc: 0.8575 - val_loss: 0.4468 - val_acc: 0.8033\n",
      "3-conv-128-nodes-0-dense-1612720285\n",
      "Train on 22415 samples, validate on 2491 samples\n",
      "Epoch 1/10\n",
      "22415/22415 [==============================] - 360s 16ms/sample - loss: 0.6349 - acc: 0.6329 - val_loss: 0.5684 - val_acc: 0.7178\n",
      "Epoch 2/10\n",
      "22415/22415 [==============================] - 343s 15ms/sample - loss: 0.5131 - acc: 0.7505 - val_loss: 0.5191 - val_acc: 0.7431\n",
      "Epoch 3/10\n",
      "22415/22415 [==============================] - 337s 15ms/sample - loss: 0.4544 - acc: 0.7886 - val_loss: 0.4644 - val_acc: 0.7780\n",
      "Epoch 4/10\n",
      "22415/22415 [==============================] - 324s 14ms/sample - loss: 0.4158 - acc: 0.8086 - val_loss: 0.4303 - val_acc: 0.8009\n",
      "Epoch 5/10\n",
      "22415/22415 [==============================] - 337s 15ms/sample - loss: 0.3730 - acc: 0.8336 - val_loss: 0.4189 - val_acc: 0.8181\n",
      "Epoch 6/10\n",
      "22415/22415 [==============================] - 326s 15ms/sample - loss: 0.3409 - acc: 0.8504 - val_loss: 0.4153 - val_acc: 0.8214\n",
      "Epoch 7/10\n",
      "22415/22415 [==============================] - 337s 15ms/sample - loss: 0.3133 - acc: 0.8608 - val_loss: 0.4258 - val_acc: 0.8125\n",
      "Epoch 8/10\n",
      "22415/22415 [==============================] - 333s 15ms/sample - loss: 0.2744 - acc: 0.8833 - val_loss: 0.4379 - val_acc: 0.8153\n",
      "Epoch 9/10\n",
      "22415/22415 [==============================] - 333s 15ms/sample - loss: 0.2435 - acc: 0.8969 - val_loss: 0.4644 - val_acc: 0.8041\n",
      "Epoch 10/10\n",
      "22415/22415 [==============================] - 338s 15ms/sample - loss: 0.2099 - acc: 0.9137 - val_loss: 0.4290 - val_acc: 0.8210\n",
      "1-conv-32-nodes-1-dense-1612723671\n",
      "Train on 22415 samples, validate on 2491 samples\n",
      "Epoch 1/10\n",
      "22415/22415 [==============================] - 32s 1ms/sample - loss: 0.6215 - acc: 0.6536 - val_loss: 0.5641 - val_acc: 0.7274\n",
      "Epoch 2/10\n",
      "22415/22415 [==============================] - 29s 1ms/sample - loss: 0.5347 - acc: 0.7364 - val_loss: 0.5439 - val_acc: 0.7342\n",
      "Epoch 3/10\n",
      "22415/22415 [==============================] - 29s 1ms/sample - loss: 0.4869 - acc: 0.7657 - val_loss: 0.5682 - val_acc: 0.7049\n",
      "Epoch 4/10\n",
      "22415/22415 [==============================] - 32s 1ms/sample - loss: 0.4528 - acc: 0.7862 - val_loss: 0.5339 - val_acc: 0.7363\n",
      "Epoch 5/10\n",
      "13952/22415 [=================>............] - ETA: 10s - loss: 0.4159 - acc: 0.8087"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "# more info on callbakcs: https://keras.io/callbacks/ model saver is cool too.\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "X = X/255.0\n",
    "\n",
    "dense_layers = [0, 1, 2]\n",
    "layer_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2, 3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(NAME)\n",
    "\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3, 3), input_shape=X.shape[1:]))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            for l in range(conv_layer-1):\n",
    "                model.add(Conv2D(layer_size, (3, 3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            model.add(Flatten())\n",
    "\n",
    "            for _ in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "            tensorboard = TensorBoard(log_dir=\"C:\\\\Users\\\\aggelos\\\\sentex\\\\deep learning with  python, tensorflow, keras\\\\logs\\\\{}\".format(NAME))\n",
    "\n",
    "            model.compile(loss='binary_crossentropy',\n",
    "                          optimizer='adam',\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "            model.fit(X, y, \n",
    "                      batch_size=32,\n",
    "                      epochs=10, \n",
    "                      validation_split=0.1,\n",
    "                      callbacks = [tensorboard])\n",
    "\n",
    "\n",
    "            # model.save('CNN.model')\n",
    "\n",
    "\n",
    "#   after running these we see that the best choices are 0 dense, 3 conv (we continue with the 3 nodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
